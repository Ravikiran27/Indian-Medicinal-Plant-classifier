{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f030b2ba",
   "metadata": {},
   "source": [
    "## How to use on Kaggle\n",
    "\n",
    "1. Open this notebook on Kaggle and add the dataset input: `indian-medicinal-plant-image-dataset`.\n",
    "2. In the right sidebar, set Accelerator to a GPU (P100/T4/V100). Internet is not required.\n",
    "3. Click “Save & Run All”.\n",
    "4. Artifacts will be saved under `/kaggle/working/impc_outputs/`:\n",
    "   - `best_model.pth` – PyTorch weights\n",
    "   - `model.torchscript.pt` – TorchScript for production\n",
    "   - `model.onnx` – ONNX export\n",
    "   - `labels.json`, `metrics.json`, `train_history.json`\n",
    "\n",
    "Tip: You can tune `CFG` in the next cell to change epochs, model, image size, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6e807",
   "metadata": {},
   "source": [
    "# Indian Medicinal Plant Classifier – Kaggle-ready\n",
    "\n",
    "This notebook fine-tunes a modern pretrained CNN on the Indian Medicinal Plant Image Dataset hosted on Kaggle, produces a professional analytics dashboard, and exports ready-to-use model artifacts (PyTorch, TorchScript, ONNX) to `/kaggle/working` for submission or reuse.\n",
    "\n",
    "Highlights\n",
    "- Robust train/val/test split from foldered classes\n",
    "- Strong augmentations and mixed-precision (AMP) for fast training on P100\n",
    "- OneCycleLR scheduler and label smoothing for stable convergence\n",
    "- Metrics: accuracy, macro F1, confusion matrix, per-class report\n",
    "- Plotly dashboard with learning curves and per-class performance\n",
    "- Exports: `best_model.pth`, `labels.json`, `model.torchscript.pt`, `model.onnx`, `metrics.json`\n",
    "\n",
    "Notes\n",
    "- Dataset path is auto-detected under `/kaggle/input/indian-medicinal-plant-image-dataset/Medicinal plant dataset`.\n",
    "- All outputs are written to `/kaggle/working` so they persist when you “Save & Run All”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and version checks\n",
    "import os, sys, json, random, math, time, gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as tvm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print('Python', sys.version)\n",
    "print('Torch', torch.__version__, '| CUDA available:', torch.cuda.is_available())\n",
    "print('Torchvision', tvm.__name__)\n",
    "\n",
    "# Base directories (Kaggle setup)\n",
    "KAGGLE_INPUT = Path('/kaggle/input')\n",
    "KAGGLE_WORKING = Path('/kaggle/working')\n",
    "DATASET_ROOT = KAGGLE_INPUT / 'indian-medicinal-plant-image-dataset' / 'Medicinal plant dataset'\n",
    "assert DATASET_ROOT.exists(), f\"Dataset folder not found at: {DATASET_ROOT}. Add the dataset as input in Kaggle.\"\n",
    "\n",
    "OUTPUT_DIR = KAGGLE_WORKING / 'impc_outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Data root:', DATASET_ROOT)\n",
    "print('Output dir:', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (adjust as needed)\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    seed: int = 42\n",
    "    img_size: int = 256           # training crop size\n",
    "    train_batch_size: int = 32\n",
    "    valid_batch_size: int = 64\n",
    "    num_workers: int = 2\n",
    "    epochs: int = 10\n",
    "    base_lr: float = 3e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    label_smoothing: float = 0.1\n",
    "    model_name: str = 'efficientnet_b0'  # ['efficientnet_b0','resnet50','convnext_tiny'] depending on torchvision version\n",
    "    mixup_alpha: float = 0.0       # set >0.0 to enable MixUp\n",
    "    cutmix_alpha: float = 0.0      # set >0.0 to enable CutMix\n",
    "    train_val_split: float = 0.15  # 15% validation\n",
    "    train_test_split: float = 0.15 # 15% test\n",
    "    early_stopping_patience: int = 5\n",
    "    freeze_backbone_epochs: int = 0  # set 1-2 if you want to warm up classifier first\n",
    "    fp16: bool = True\n",
    "\n",
    "cfg = CFG()\n",
    "print(asdict(cfg))\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58878470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility and helpers\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "IMG_EXTS = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}\n",
    "\n",
    "def list_images(root: Path):\n",
    "    classes = sorted([d.name for d in root.iterdir() if d.is_dir()])\n",
    "    samples, labels = [], []\n",
    "    for idx, cls in enumerate(classes):\n",
    "        for p in (root/cls).rglob('*'):\n",
    "            if p.suffix.lower() in IMG_EXTS:\n",
    "                samples.append(p)\n",
    "                labels.append(idx)\n",
    "    return classes, np.array(samples), np.array(labels, dtype=np.int64)\n",
    "\n",
    "classes, all_paths, all_labels = list_images(DATASET_ROOT)\n",
    "num_classes = len(classes)\n",
    "print(f\"Found {len(all_paths)} images across {num_classes} classes.\")\n",
    "\n",
    "# Save label mapping\n",
    "label_map = {i:c for i,c in enumerate(classes)}\n",
    "with open(OUTPUT_DIR/'labels.json','w') as f:\n",
    "    json.dump(label_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test split (stratified)\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=cfg.train_val_split + cfg.train_test_split, random_state=cfg.seed)\n",
    "train_idx, temp_idx = next(sss1.split(all_paths, all_labels))\n",
    "\n",
    "paths_train, labels_train = all_paths[train_idx], all_labels[train_idx]\n",
    "paths_temp, labels_temp = all_paths[temp_idx], all_labels[temp_idx]\n",
    "\n",
    "val_ratio_of_temp = cfg.train_val_split / (cfg.train_val_split + cfg.train_test_split)\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=1 - val_ratio_of_temp, random_state=cfg.seed)\n",
    "val_idx, test_idx = next(sss2.split(paths_temp, labels_temp))\n",
    "\n",
    "paths_val, labels_val = paths_temp[val_idx], labels_temp[val_idx]\n",
    "paths_test, labels_test = paths_temp[test_idx], labels_temp[test_idx]\n",
    "\n",
    "print(f\"Split -> train: {len(paths_train)}, val: {len(paths_val)}, test: {len(paths_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms and Dataset\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.RandomResizedCrop(cfg.img_size, scale=(0.7, 1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(p=0.2),\n",
    "    T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "    T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "valid_tfms = T.Compose([\n",
    "    T.Resize(int(cfg.img_size*1.15)),\n",
    "    T.CenterCrop(cfg.img_size),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = list(map(str, paths))\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        img = Image.open(p).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        target = int(self.labels[idx])\n",
    "        return img, target\n",
    "\n",
    "train_ds = ImageDataset(paths_train, labels_train, train_tfms)\n",
    "val_ds   = ImageDataset(paths_val, labels_val, valid_tfms)\n",
    "test_ds  = ImageDataset(paths_test, labels_test, valid_tfms)\n",
    "\n",
    "# Balanced sampling for training if classes are imbalanced\n",
    "class_counts = np.bincount(labels_train, minlength=num_classes)\n",
    "class_weights = 1.0 / np.clip(class_counts, 1, None)\n",
    "weights = class_weights[labels_train]\n",
    "sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.train_batch_size, sampler=sampler,\n",
    "                          num_workers=cfg.num_workers, pin_memory=True, persistent_workers=False)\n",
    "val_loader   = DataLoader(val_ds, batch_size=cfg.valid_batch_size, shuffle=False,\n",
    "                          num_workers=cfg.num_workers, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=cfg.valid_batch_size, shuffle=False,\n",
    "                          num_workers=cfg.num_workers, pin_memory=True)\n",
    "\n",
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96aea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model factory\n",
    "\n",
    "def build_model(model_name: str, num_classes: int):\n",
    "    model_name = model_name.lower()\n",
    "\n",
    "    def safe_load(fn_with_weights, fn_no_weights):\n",
    "        try:\n",
    "            return fn_with_weights()\n",
    "        except Exception as e:\n",
    "            print(f\"[Info] Could not load pretrained weights (likely no internet/cache). Falling back to non-pretrained. Error: {str(e)[:120]}\")\n",
    "            return fn_no_weights()\n",
    "\n",
    "    if model_name == 'efficientnet_b0':\n",
    "        def with_w():\n",
    "            weights = getattr(tvm, 'EfficientNet_B0_Weights', None)\n",
    "            if weights is not None:\n",
    "                return tvm.efficientnet_b0(weights=weights.IMAGENET1K_V1)\n",
    "            return tvm.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "        def no_w():\n",
    "            return tvm.efficientnet_b0(weights=None)\n",
    "        model = safe_load(with_w, no_w)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        def with_w():\n",
    "            weights = getattr(tvm, 'ResNet50_Weights', None)\n",
    "            if weights is not None:\n",
    "                return tvm.resnet50(weights=weights.IMAGENET1K_V2)\n",
    "            return tvm.resnet50(weights='IMAGENET1K_V2')\n",
    "        def no_w():\n",
    "            return tvm.resnet50(weights=None)\n",
    "        model = safe_load(with_w, no_w)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    elif model_name == 'convnext_tiny' and hasattr(tvm, 'convnext_tiny'):\n",
    "        def with_w():\n",
    "            weights = getattr(tvm, 'ConvNeXt_Tiny_Weights', None)\n",
    "            return tvm.convnext_tiny(weights=weights.IMAGENET1K_V1 if weights else 'IMAGENET1K_V1')\n",
    "        def no_w():\n",
    "            return tvm.convnext_tiny(weights=None)\n",
    "        model = safe_load(with_w, no_w)\n",
    "        in_features = model.classifier[2].in_features\n",
    "        model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        print('Unknown model, defaulting to resnet50')\n",
    "        def with_w():\n",
    "            weights = getattr(tvm, 'ResNet50_Weights', None)\n",
    "            return tvm.resnet50(weights=weights.IMAGENET1K_V2 if weights else 'IMAGENET1K_V2')\n",
    "        def no_w():\n",
    "            return tvm.resnet50(weights=None)\n",
    "        model = safe_load(with_w, no_w)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(cfg.model_name, num_classes).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.base_lr, weight_decay=cfg.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=cfg.base_lr, steps_per_epoch=len(train_loader), epochs=cfg.epochs\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=cfg.fp16 and DEVICE.type=='cuda')\n",
    "\n",
    "print('Model built:', cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397899c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loops\n",
    "\n",
    "def accuracy(outputs, targets):\n",
    "    preds = outputs.argmax(1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    running_loss = 0.0\n",
    "    for imgs, targets in loader:\n",
    "        imgs, targets = imgs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(enabled=cfg.fp16 and DEVICE.type=='cuda'):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, targets)\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        all_preds.append(logits.argmax(1).detach().cpu().numpy())\n",
    "        all_targets.append(targets.detach().cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    val_loss = running_loss / len(loader.dataset)\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    return val_loss, acc, f1, all_targets, all_preds\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    best_f1, best_state, epochs_no_improve = -1.0, None, 0\n",
    "    history = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[], \"val_f1\":[], \"lr\": []}\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        if cfg.freeze_backbone_epochs and epoch < cfg.freeze_backbone_epochs:\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'classifier' not in name and (not name.endswith('fc.weight') and not name.endswith('fc.bias')):\n",
    "                    p.requires_grad = False\n",
    "        else:\n",
    "            for p in model.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.epochs}\", leave=False)\n",
    "        running_loss, running_acc, n = 0.0, 0.0, 0\n",
    "        \n",
    "        for imgs, targets in pbar:\n",
    "            imgs, targets = imgs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=cfg.fp16 and DEVICE.type=='cuda'):\n",
    "                logits = model(imgs)\n",
    "                loss = criterion(logits, targets)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            running_acc += (logits.argmax(1) == targets).float().sum().item()\n",
    "            n += imgs.size(0)\n",
    "            pbar.set_postfix({\"loss\": running_loss/n, \"acc\": running_acc/n, \"lr\": scheduler.get_last_lr()[0]})\n",
    "\n",
    "        train_loss = running_loss / n\n",
    "        train_acc = running_acc / n\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['lr'].append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}: train_loss={train_loss:.4f} acc={train_acc:.4f} | val_loss={val_loss:.4f} val_acc={val_acc:.4f} val_f1={val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping & checkpoint\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_state = {k: v.cpu() for k,v in model.state_dict().items()}\n",
    "            torch.save(best_state, OUTPUT_DIR/'best_model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= cfg.early_stopping_patience:\n",
    "                print('Early stopping.')\n",
    "                break\n",
    "\n",
    "    # Load best\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, history\n",
    "\n",
    "model, history = train_model(model, train_loader, val_loader)\n",
    "with open(OUTPUT_DIR/'train_history.json','w') as f:\n",
    "    json.dump(history, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be59c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard: learning curves\n",
    "hist = history\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=(\n",
    "    'Loss','Accuracy','Val F1','Learning Rate'))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=hist['train_loss'], name='train_loss'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(y=hist['val_loss'], name='val_loss'), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(y=hist['train_acc'], name='train_acc'), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(y=hist['val_acc'], name='val_acc'), row=1, col=2)\n",
    "\n",
    "fig.add_trace(go.Scatter(y=hist['val_f1'], name='val_f1'), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(y=hist['lr'], name='lr'), row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=700, width=1000, title_text='Training Dashboard', showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on validation and test sets\n",
    "val_loss, val_acc, val_f1, val_t, val_p = evaluate(model, val_loader)\n",
    "print(f\"Validation -> loss={val_loss:.4f}, acc={val_acc:.4f}, f1={val_f1:.4f}\")\n",
    "\n",
    "te_loss, te_acc, te_f1, te_t, te_p = evaluate(model, test_loader)\n",
    "print(f\"Test -> loss={te_loss:.4f}, acc={te_acc:.4f}, f1={te_f1:.4f}\")\n",
    "\n",
    "# Detailed classification report (test)\n",
    "report = classification_report(te_t, te_p, target_names=classes, output_dict=True)\n",
    "with open(OUTPUT_DIR/'classification_report.json','w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "# Confusion matrix (test)\n",
    "cm = confusion_matrix(te_t, te_p, labels=list(range(num_classes)))\n",
    "cm_fig = px.imshow(cm, text_auto=True, color_continuous_scale='Blues',\n",
    "                   labels=dict(x='Predicted', y='True', color='Count'),\n",
    "                   x=classes, y=classes)\n",
    "cm_fig.update_layout(title='Confusion Matrix – Test')\n",
    "cm_fig.show()\n",
    "\n",
    "# Per-class F1\n",
    "per_class_f1 = [report[c]['f1-score'] for c in classes]\n",
    "bar_fig = px.bar(x=classes, y=per_class_f1, labels={'x':'Class','y':'F1-score'}, title='Per-Class F1 (Test)')\n",
    "bar_fig.update_xaxes(tickangle=45)\n",
    "bar_fig.show()\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'val': {'loss': val_loss, 'acc': val_acc, 'f1': val_f1},\n",
    "    'test': {'loss': te_loss, 'acc': te_acc, 'f1': te_f1}\n",
    "}\n",
    "with open(OUTPUT_DIR/'metrics.json','w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print('Metrics saved to', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export: PyTorch state dict, TorchScript, ONNX\n",
    "model.eval()\n",
    "\n",
    "# Save state dict (already saved best during training, but ensure copy)\n",
    "best_pth = OUTPUT_DIR/'best_model.pth'\n",
    "if not best_pth.exists():\n",
    "    torch.save({k: v.cpu() for k,v in model.state_dict().items()}, best_pth)\n",
    "print('Saved:', best_pth)\n",
    "\n",
    "# TorchScript\n",
    "example = torch.randn(1, 3, cfg.img_size, cfg.img_size).to(DEVICE)\n",
    "traced = torch.jit.trace(model, example)\n",
    "script_path = OUTPUT_DIR/'model.torchscript.pt'\n",
    "traced.save(str(script_path))\n",
    "print('Saved:', script_path)\n",
    "\n",
    "# ONNX (dynamic axes for batch)\n",
    "onx_path = OUTPUT_DIR/'model.onnx'\n",
    "dummy = torch.randn(1, 3, cfg.img_size, cfg.img_size, device=DEVICE)\n",
    "torch.onnx.export(\n",
    "    model, dummy, str(onx_path), input_names=['images'], output_names=['logits'],\n",
    "    dynamic_axes={'images': {0: 'batch'}, 'logits': {0: 'batch'}}, opset_version=12\n",
    ")\n",
    "print('Saved:', onx_path)\n",
    "\n",
    "print('Label map at:', OUTPUT_DIR/'labels.json')\n",
    "print('Artifacts ready in /kaggle/working/impc_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference demo with TTA\n",
    "from torchvision.transforms.functional import resize, center_crop\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_batch(imgs):\n",
    "    model.eval()\n",
    "    with torch.cuda.amp.autocast(enabled=cfg.fp16 and DEVICE.type=='cuda'):\n",
    "        logits = model(imgs)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "    return probs\n",
    "\n",
    "@torch.no_grad()\n",
    "def tta_predict(img):\n",
    "    # img: tensor CxHxW normalized\n",
    "    augmentations = [lambda x:x,\n",
    "                     T.RandomHorizontalFlip(p=1.0),\n",
    "                     T.RandomVerticalFlip(p=1.0)]\n",
    "    probs = []\n",
    "    for aug in augmentations:\n",
    "        aug_img = aug(img)\n",
    "        probs.append(predict_batch(aug_img.unsqueeze(0).to(DEVICE)))\n",
    "    return torch.stack(probs).mean(0).squeeze(0)\n",
    "\n",
    "# Show a few predictions from test set\n",
    "n_show = min(12, len(test_ds))\n",
    "sample_idx = np.random.choice(len(test_ds), size=n_show, replace=False)\n",
    "\n",
    "rows, cols = math.ceil(n_show/4), 4\n",
    "fig = make_subplots(rows=rows, cols=cols, subplot_titles=[f\"true:{classes[int(labels_test[i])] }\" for i in sample_idx])\n",
    "\n",
    "for k, i in enumerate(sample_idx):\n",
    "    img, true_lbl = test_ds[i]\n",
    "    prob = tta_predict(img)\n",
    "    pred_idx = int(prob.argmax().item())\n",
    "    pred_cls = classes[pred_idx]\n",
    "\n",
    "    # Denormalize for display\n",
    "    img_disp = img.clone()\n",
    "    for c,(m,s) in enumerate(zip(IMAGENET_MEAN, IMAGENET_STD)):\n",
    "        img_disp[c] = img_disp[c]*s + m\n",
    "    img_disp = (img_disp.clamp(0,1).permute(1,2,0).cpu().numpy()*255).astype(np.uint8)\n",
    "\n",
    "    r, c = k//cols + 1, k%cols + 1\n",
    "    fig.add_trace(go.Image(z=img_disp), row=r, col=c)\n",
    "    fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "    fig.layout.annotations[k].text += f\" | pred:{pred_cls}\"\n",
    "\n",
    "fig.update_layout(height=300*rows, width=250*cols, title_text='Sample Test Predictions (TTA)')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
